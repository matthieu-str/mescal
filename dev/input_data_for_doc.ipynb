{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generate the input data files to be displayed in the documentation",
   "id": "c3812a882b2bd0e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:39.465961Z",
     "start_time": "2025-12-01T20:49:38.348497Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "6d5120c84eb634c8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:39.870388Z",
     "start_time": "2025-12-01T20:49:39.472979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mapping = pd.read_csv('../dev/energyscope_data/CA-QC/mapping.csv')\n",
    "lifetime = pd.read_csv('../dev/energyscope_data/CA-QC/lifetime.csv')\n",
    "model = pd.read_csv('../dev/energyscope_data/CA-QC/model.csv')\n",
    "tech_es = pd.read_csv('../dev/energyscope_data/CA-QC/technology_dictionary.csv')\n",
    "res_es = pd.read_excel('../dev/energyscope_data/CA-QC/resource_dictionary.xlsx')"
   ],
   "id": "189dc16a699947a9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:40.386414Z",
     "start_time": "2025-12-01T20:49:40.259822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Allows to keep formulas in Excel files\n",
    "from openpyxl import load_workbook\n",
    "wb = load_workbook(filename = '../dev/energyscope_data/CA-QC/unit_conversion.xlsx')\n",
    "conversion_factors = pd.DataFrame(wb[wb.sheetnames[0]].values)\n",
    "new_header = conversion_factors.iloc[0]\n",
    "conversion_factors = conversion_factors[1:]\n",
    "conversion_factors.columns = new_header"
   ],
   "id": "8f6aa266feb29793",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:40.406172Z",
     "start_time": "2025-12-01T20:49:40.394423Z"
    }
   },
   "cell_type": "code",
   "source": "len(mapping[mapping.Type.isin(['Construction', 'Operation', 'Resource', 'Flow'])].Name.unique())",
   "id": "37370a8fdbdfebb6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "732"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:40.439699Z",
     "start_time": "2025-12-01T20:49:40.423701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# drop rows with Type not in Construction, Operation, Resource\n",
    "mapping = mapping[mapping.Type.isin(['Construction', 'Operation', 'Resource', 'Flow'])]\n",
    "conversion_factors = conversion_factors[conversion_factors.Type.isin(['Construction', 'Operation', 'Resource', 'Flow'])]"
   ],
   "id": "7798e7a08da6dd01",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:40.465962Z",
     "start_time": "2025-12-01T20:49:40.457962Z"
    }
   },
   "cell_type": "code",
   "source": "mapping.drop(columns=['Database', 'Location'], inplace=True)",
   "id": "caf89b6dc2f59886",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:40.506236Z",
     "start_time": "2025-12-01T20:49:40.483723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mapping['Name'] = mapping['Name'].str.replace('_SD$', '', regex=True)\n",
    "mapping['Name'] = mapping['Name'].str.replace('_MD$', '', regex=True)\n",
    "mapping['Name'] = mapping['Name'].str.replace('_LD$', '', regex=True)\n",
    "mapping['Name'] = mapping['Name'].str.replace('_ELD$', '', regex=True)\n",
    "\n",
    "conversion_factors['Name'] = conversion_factors['Name'].str.replace('_SD$', '', regex=True)\n",
    "conversion_factors['Name'] = conversion_factors['Name'].str.replace('_MD$', '', regex=True)\n",
    "conversion_factors['Name'] = conversion_factors['Name'].str.replace('_LD$', '', regex=True)\n",
    "conversion_factors['Name'] = conversion_factors['Name'].str.replace('_ELD$', '', regex=True)\n",
    "\n",
    "model['Name'] = model['Name'].str.replace('_SD$', '', regex=True)\n",
    "model['Name'] = model['Name'].str.replace('_MD$', '', regex=True)\n",
    "model['Name'] = model['Name'].str.replace('_LD$', '', regex=True)\n",
    "model['Name'] = model['Name'].str.replace('_ELD$', '', regex=True)\n",
    "\n",
    "model['Flow'] = model['Flow'].str.replace('_SD$', '', regex=True)\n",
    "model['Flow'] = model['Flow'].str.replace('_MD$', '', regex=True)\n",
    "model['Flow'] = model['Flow'].str.replace('_LD$', '', regex=True)\n",
    "model['Flow'] = model['Flow'].str.replace('_ELD$', '', regex=True)"
   ],
   "id": "489e7a2842078c9e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:40.546715Z",
     "start_time": "2025-12-01T20:49:40.522731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mapping['Name'] = mapping['Name'].str.replace('_SD', '', regex=True)\n",
    "mapping['Name'] = mapping['Name'].str.replace('_MD', '', regex=True)\n",
    "mapping['Name'] = mapping['Name'].str.replace('_LD', '', regex=True)\n",
    "mapping['Name'] = mapping['Name'].str.replace('_ELD', '', regex=True)\n",
    "\n",
    "conversion_factors['Name'] = conversion_factors['Name'].str.replace('_SD', '', regex=True)\n",
    "conversion_factors['Name'] = conversion_factors['Name'].str.replace('_MD', '', regex=True)\n",
    "conversion_factors['Name'] = conversion_factors['Name'].str.replace('_LD', '', regex=True)\n",
    "conversion_factors['Name'] = conversion_factors['Name'].str.replace('_ELD', '', regex=True)\n",
    "\n",
    "model['Name'] = model['Name'].str.replace('_SD', '', regex=True)\n",
    "model['Name'] = model['Name'].str.replace('_MD', '', regex=True)\n",
    "model['Name'] = model['Name'].str.replace('_LD', '', regex=True)\n",
    "model['Name'] = model['Name'].str.replace('_ELD', '', regex=True)\n",
    "\n",
    "model['Flow'] = model['Flow'].str.replace('_SD', '', regex=True)\n",
    "model['Flow'] = model['Flow'].str.replace('_MD', '', regex=True)\n",
    "model['Flow'] = model['Flow'].str.replace('_LD', '', regex=True)\n",
    "model['Flow'] = model['Flow'].str.replace('_ELD', '', regex=True)"
   ],
   "id": "d993d2dcb285e0fb",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:40.578679Z",
     "start_time": "2025-12-01T20:49:40.562326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mapping.drop_duplicates(inplace=True)\n",
    "conversion_factors.drop_duplicates(inplace=True)\n",
    "model.drop_duplicates(inplace=True)"
   ],
   "id": "5a274743c505bac0",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:40.602345Z",
     "start_time": "2025-12-01T20:49:40.595824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tech_es_dict = dict(zip(tech_es['Programming name'], tech_es['Long name']))\n",
    "res_es_dict = dict(zip(res_es['Name'], res_es['Description']))"
   ],
   "id": "9d3d6036955844bc",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:40.651938Z",
     "start_time": "2025-12-01T20:49:40.638867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "augmented_tech_es_dict = tech_es_dict.copy()\n",
    "for key, value in tech_es_dict.items():\n",
    "    augmented_tech_es_dict[key+'_PLANT'] = value + ' (plant)'\n",
    "    augmented_tech_es_dict[key+'_DECOM'] = value + ' (decommissioning)'\n",
    "    augmented_tech_es_dict[key+'_PLANT_DECOM'] = value + ' (plant decommissioning)'\n",
    "    augmented_tech_es_dict[key+'_COGEN'] = value + ' (co-generation unit)'\n",
    "    augmented_tech_es_dict[key+'_TANK'] = value + ' (storage tank)'\n",
    "    augmented_tech_es_dict[key+'_BOILER'] = value + ' (boiler)'\n",
    "    augmented_tech_es_dict[key+'_CHP'] = value + ' (co-generation unit, components for heat and electricity)'\n",
    "    augmented_tech_es_dict[key+'_HEAT'] = value + ' (co-generation unit, components for heat)'\n",
    "    augmented_tech_es_dict[key+'_ELEC'] = value + ' (co-generation unit, components for electricity)'\n",
    "    augmented_tech_es_dict[key+'_TURBINE'] = value + ' (co-generation unit)'\n",
    "    augmented_tech_es_dict[key+'_HEX'] = value + ' (heat exchanger)'\n",
    "    augmented_tech_es_dict[key+'_DUST'] = value + ' (dust collector)'\n",
    "    augmented_tech_es_dict[key+'_STACK'] = value + ' (stack)'\n",
    "    augmented_tech_es_dict[key+'_STACK_DECOM'] = value + ' (stack decommissioning)'\n",
    "    augmented_tech_es_dict[key+'_HP'] = value + ' (heat pump)'\n",
    "    augmented_tech_es_dict[key+'_LOC'] = value + ' (locomotive)'\n",
    "    augmented_tech_es_dict[key+'_WAG'] = value + ' (wagon)'\n",
    "    augmented_tech_es_dict[key+'_FIXED'] = value + ' (fixed parts)'\n",
    "    augmented_tech_es_dict[key+'_MOVING'] = value + ' (moving parts)'\n",
    "    augmented_tech_es_dict[key+'_CONNECTION'] = value + ' (connection)'"
   ],
   "id": "a75f79dfe48600d3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:40.670127Z",
     "start_time": "2025-12-01T20:49:40.657948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mapping['Full name'] = mapping['Name'].map(augmented_tech_es_dict)\n",
    "conversion_factors['Full name'] = conversion_factors['Name'].map(augmented_tech_es_dict)\n",
    "model['Description (name)'] = model['Name'].map(augmented_tech_es_dict)\n",
    "model['Description (flow)'] = model['Flow'].map(res_es_dict)"
   ],
   "id": "6edaddeb5fd4abe9",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:40.708400Z",
     "start_time": "2025-12-01T20:49:40.695894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mapping.drop(mapping[mapping['Full name'].isna()].index, inplace=True)\n",
    "conversion_factors.drop(conversion_factors[conversion_factors['Full name'].isna()].index, inplace=True)\n",
    "model.drop(model[model['Description (name)'].isna()].index, inplace=True)"
   ],
   "id": "76b6495f6553f6f7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:40.763338Z",
     "start_time": "2025-12-01T20:49:40.728049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mapping.drop(columns=['Name']).rename(columns={'Full name': 'Name'})[['Name', 'Type', 'Product', 'Activity']].to_csv('../docs/_static/mapping_generic.csv', index=False)\n",
    "mapping.rename(columns={'Full name': 'Description'})[['Name', 'Type', 'Description', 'Product', 'Activity']].to_csv('../docs/_static/mapping_energyscope.csv', index=False)\n",
    "model.drop(columns=['Name', 'Flow']).rename(columns={'Description (name)': 'Name', 'Description (flow)': 'Flow'})[['Name', 'Flow', 'Amount']].to_csv('../docs/_static/model_generic.csv', index=False)\n",
    "model.to_csv('../docs/_static/model_energyscope.csv', index=False)"
   ],
   "id": "68d0a3c3e45483bc",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:40.889658Z",
     "start_time": "2025-12-01T20:49:40.779193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pybtex.database import parse_file\n",
    "from pybtex.scanner import PybtexSyntaxError\n",
    "from pybtex.richtext import Text\n",
    "import re"
   ],
   "id": "5aed3a1860bfc7a0",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:40.915479Z",
     "start_time": "2025-12-01T20:49:40.908478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Regex to match \\cite{key1,key2,...}\n",
    "pattern = re.compile(r\"\\\\cite\\{([^}]+)\\}\")\n",
    "\n",
    "# Collect all keys from all text cells\n",
    "keys = set()\n",
    "\n",
    "for cell in conversion_factors['Assumptions & Sources'].astype(str):\n",
    "    matches = pattern.findall(cell)\n",
    "    for match in matches:\n",
    "        for key in match.split(\",\"):\n",
    "            keys.add(key.strip())"
   ],
   "id": "203db438906ecacc",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:40.999751Z",
     "start_time": "2025-12-01T20:49:40.935177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    bib_data = parse_file('../dev/energyscope_data/CA-QC/conv.bib')\n",
    "except PybtexSyntaxError as e:\n",
    "    print(\"‚ùå Error parsing BibTeX file:\", e)\n",
    "    raise"
   ],
   "id": "486214b25bcc557",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:41.025812Z",
     "start_time": "2025-12-01T20:49:41.020439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_latex_to_unicode(text):\n",
    "    \"\"\"Convert LaTeX accents and remove braces safely using pybtex.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # Convert LaTeX markup to unicode using pybtex itself\n",
    "    if isinstance(text, Text):\n",
    "        text = str(text)\n",
    "    # Remove LaTeX-style escapes like {\\'e}\n",
    "    text = re.sub(r\"\\\\[a-zA-Z]+\\{([^}]+)\\}\", r\"\\1\", text)\n",
    "    # Remove leftover braces\n",
    "    text = re.sub(r\"[{}]\", \"\", text)\n",
    "    return text.strip()"
   ],
   "id": "5e2b687b06cc1c37",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:41.053953Z",
     "start_time": "2025-12-01T20:49:41.049116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_author(persons):\n",
    "    \"\"\"Format first author name, handle multi-part last names.\"\"\"\n",
    "    if not persons:\n",
    "        return \"Unknown\"\n",
    "    author = persons[0]\n",
    "    last_name = \" \".join(author.last_names)\n",
    "    return clean_latex_to_unicode(last_name)"
   ],
   "id": "97ddf82fa4e2bcc2",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:41.080585Z",
     "start_time": "2025-12-01T20:49:41.074317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cite_replace(text):\n",
    "    \"\"\"Replace \\cite{key} with (Author, Year) cleanly.\"\"\"\n",
    "    def repl(match):\n",
    "        keys = match.group(1).split(\",\")\n",
    "        citations = []\n",
    "        for key in keys:\n",
    "            key = key.strip()\n",
    "            try:\n",
    "                entry = bib_data.entries[key]\n",
    "                if \"author\" in entry.persons and entry.persons[\"author\"]:\n",
    "                    author = format_author(entry.persons[\"author\"])\n",
    "                elif \"editor\" in entry.persons and entry.persons[\"editor\"]:\n",
    "                    author = format_author(entry.persons[\"editor\"])\n",
    "                else:\n",
    "                    # fallback for organizations or institutions\n",
    "                    author = entry.fields.get(\"organization\") or entry.fields.get(\"title\", \"Unknown\")\n",
    "                    author = clean_latex_to_unicode(author)\n",
    "                year = entry.fields.get(\"year\", \"n.d.\")\n",
    "                citations.append(f\"{author}, {year}\")\n",
    "            except KeyError:\n",
    "                citations.append(f\"???, {key}\")\n",
    "        return \"(\" + \"; \".join(citations) + \")\"\n",
    "\n",
    "    return re.sub(r\"\\\\cite\\{([^}]+)\\}\", repl, text)"
   ],
   "id": "3b581adcf45d2050",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:41.113759Z",
     "start_time": "2025-12-01T20:49:41.103533Z"
    }
   },
   "cell_type": "code",
   "source": "conversion_factors[\"Assumptions & Sources\"] = conversion_factors[\"Assumptions & Sources\"].astype(str).apply(cite_replace)",
   "id": "9c2550d6121c04d5",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:41.145749Z",
     "start_time": "2025-12-01T20:49:41.138321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conversion_factors[\"Assumptions & Sources\"] = conversion_factors[\"Assumptions & Sources\"].replace(\"\\\\'e\", \"e\")\n",
    "conversion_factors[\"Assumptions & Sources\"] = conversion_factors[\"Assumptions & Sources\"].replace('\\\\\"o', \"o\")"
   ],
   "id": "2573f9aefdd1af82",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T20:49:41.352042Z",
     "start_time": "2025-12-01T20:49:41.168948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conversion_factors.rename(columns={'ESM': 'ESM unit', 'LCA': 'LCA unit'}).drop(columns=['Name']).rename(columns={'Full name': 'Name'})[['Name', 'Type', 'Value', 'LCA unit', 'ESM unit', 'Assumptions & Sources']].to_csv('../docs/_static/unit_conversion_generic.csv', index=False)\n",
    "conversion_factors.rename(columns={'Full name': 'Description'})[['Name', 'Type', 'Description', 'Value', 'LCA', 'ESM', 'Assumptions & Sources']].to_excel('../docs/_static/unit_conversion_energyscope.xlsx', index=False)"
   ],
   "id": "2b2776f2d67b8e5",
   "outputs": [],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
