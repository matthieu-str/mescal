{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Consolidating several mappings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bw2data as bd\n",
    "from mescal import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:04.671173Z",
     "start_time": "2024-07-03T20:15:56.554962Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:04.820325Z",
     "start_time": "2024-07-03T20:16:04.673187Z"
    }
   },
   "cell_type": "code",
   "source": "bd.projects.set_current('ei3.8-mescal')",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "tech_CH = pd.read_csv('energyscope_data/QC/hidden/tech_CH.csv') # mapping from ecoinvent 3.8 for CH\n",
    "tech_QC = pd.read_csv('energyscope_data/QC/hidden/tech_QC.csv') # mapping from ecoinvent 3.8 and premise specific for QC\n",
    "comp_CH = pd.read_excel('energyscope_data/QC/hidden/techno_compositions_CH.xlsx') # list of compositions of technologies with premise mapping for CH\n",
    "comp_QC = pd.read_excel('energyscope_data/QC/hidden/techno_compositions_QC.xlsx') # list of compositions of technologies with premise mapping for QC\n",
    "dict_ES = pd.read_csv('energyscope_data/QC/hidden/Technology_Dictionary_v2.csv')\n",
    "region_tech_ES = pd.read_excel('energyscope_data/QC/hidden/Technologies_ES_version.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:04.929519Z",
     "start_time": "2024-07-03T20:16:04.820325Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:06.727750Z",
     "start_time": "2024-07-03T20:16:06.718662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if 'Validation' in tech_CH.columns:\n",
    "    tech_CH.drop(columns='Validation', inplace=True)\n",
    "if 'Validation' in tech_QC.columns:\n",
    "    tech_QC.drop(columns='Validation', inplace=True)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mapping file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:07.960972Z",
     "start_time": "2024-07-03T20:16:07.948465Z"
    }
   },
   "cell_type": "code",
   "source": "len(tech_CH.ES_name.unique())",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### QC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start from the consolidated file of CH and add/replace what is in the tech_QC additional mapping, and filter what was only for CH using the list of technologies from ES-QC."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "region_tech_ES.dropna(subset=['ES_version'], inplace=True) # OTHER_BIOMASS to remove"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:10.251378Z",
     "start_time": "2024-07-03T20:16:10.229976Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "list_tech_QC = list(region_tech_ES[region_tech_ES.ES_version.str.contains('CA')].tech_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:10.758431Z",
     "start_time": "2024-07-03T20:16:10.740011Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:11.172814Z",
     "start_time": "2024-07-03T20:16:11.165970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sub_comp_CH = list(set([x for xs in comp_CH.iloc[:, 1:].values.tolist() for x in xs])) # list of all subcomponents for CH\n",
    "sub_comp_QC = list(set([x for xs in comp_QC.iloc[:, 1:].values.tolist() for x in xs])) # list of all subcomponents for QC"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove technologies that are not in ES-QC\n",
    "tech_not_QC = []\n",
    "\n",
    "# Operation\n",
    "for tech in list(tech_CH[tech_CH.type == 'Operation'].ES_name):\n",
    "    if tech not in list_tech_QC:\n",
    "        tech_not_QC.append(tech)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Construction\n",
    "for tech in list(tech_CH[tech_CH.type == 'Construction'].ES_name):\n",
    "    if tech in sub_comp_CH:\n",
    "        if tech not in sub_comp_QC:\n",
    "            tech_not_QC.append(tech)\n",
    "        else:\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:11.703652Z",
     "start_time": "2024-07-03T20:16:11.681964Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "list(set(tech_not_QC))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:12.478929Z",
     "start_time": "2024-07-03T20:16:12.470185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BUS_FC_HYBRID_CH4',\n",
       " 'CAR_ETOH_E85_LONGD',\n",
       " 'CAR_ETOH_E10_LOCAL',\n",
       " 'WIND',\n",
       " 'CAR_GASOLINE_LONGD',\n",
       " 'TRAIN_ELEC',\n",
       " 'CAR_DIESEL_LONGD',\n",
       " 'BUS_CNG_STOICH',\n",
       " 'CAR_PHEV_LOCAL',\n",
       " 'TRAIN_FREIGHT_WAG',\n",
       " 'CAR_MEOH_LOCAL',\n",
       " 'COACH_HY_DIESEL',\n",
       " 'CAR_ETOH_E10_LONGD',\n",
       " 'CAR_HEV_LOCAL',\n",
       " 'COMMUTER_RAIL_DIESEL',\n",
       " 'CAR_FC_CH4_LOCAL',\n",
       " 'CAR_DIESEL_LOCAL',\n",
       " 'CAR_NG_LOCAL',\n",
       " 'TRUCK_EV',\n",
       " 'CAR_GASOLINE_LOCAL',\n",
       " 'TRUCK_FC',\n",
       " 'CAR_BEV_LOWRANGE',\n",
       " 'CAR_BEV_MEDRANGE_LONGD',\n",
       " 'CAR_DME_D10_LONGD',\n",
       " 'COACH_FC_HYBRID_H2',\n",
       " 'TRAIN_FREIGHT_NG_WAG',\n",
       " 'BUS_FC_HYBRID_H2',\n",
       " 'CAR_PHEV_LONGD',\n",
       " 'COMMUTER_RAIL_ELEC',\n",
       " 'CAR_HEV_LONGD',\n",
       " 'COACH_FC_HYBRID_CH4',\n",
       " 'TRAIN_FREIGHT_LOC',\n",
       " 'TRUCK_SNG',\n",
       " 'CAR_FC_CH4_LONGD',\n",
       " 'CAR_NG_LONGD',\n",
       " 'TRAIN_FREIGHT',\n",
       " 'COACH_CNG_STOICH',\n",
       " 'CAR_BEV_MEDRANGE_LOCAL',\n",
       " 'TRUCK',\n",
       " 'TRAIN_NG',\n",
       " 'CAR_DME_D10_LOCAL',\n",
       " 'CAR_FC_H2_LOCAL',\n",
       " 'CAR_FC_H2_LONGD',\n",
       " 'TRAIN_FREIGHT_NG',\n",
       " 'TRAIN_FREIGHT_NG_LOC',\n",
       " 'CAR_MEOH_LONGD',\n",
       " 'CAR_ETOH_E85_LOCAL']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "tech_CH_filtered = tech_CH.drop(index=tech_CH[tech_CH.ES_name.isin(tech_not_QC)].index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:13.093063Z",
     "start_time": "2024-07-03T20:16:13.033450Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove the LCI datasets that need to be updated from the CH list\n",
    "update_constr = []\n",
    "for tech in list(tech_CH[tech_CH.type == 'Construction'].ES_name):\n",
    "    if (tech in list(tech_CH[tech_CH.type == 'Construction'].ES_name)) & (tech in list(tech_QC[tech_QC.type == 'Construction'].ES_name)):\n",
    "        update_constr.append(tech)\n",
    "\n",
    "update_op = []\n",
    "for tech in list(tech_CH[tech_CH.type == 'Operation'].ES_name):\n",
    "    if (tech in list(tech_CH[tech_CH.type == 'Operation'].ES_name)) & (tech in list(tech_QC[tech_QC.type == 'Operation'].ES_name)):\n",
    "        update_op.append(tech)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:17.876792Z",
     "start_time": "2024-07-03T20:16:17.625046Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "tech_CH_filtered.drop(index=tech_CH_filtered[(tech_CH_filtered.ES_name.isin(update_constr)) & (tech_CH_filtered.type == 'Construction')].index, inplace=True)\n",
    "tech_CH_filtered.drop(index=tech_CH_filtered[(tech_CH_filtered.ES_name.isin(update_op)) & (tech_CH_filtered.type == 'Operation')].index, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:18.438638Z",
     "start_time": "2024-07-03T20:16:18.423894Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "tech_consolidated_QC = pd.concat([tech_CH_filtered, tech_QC])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:18.615642Z",
     "start_time": "2024-07-03T20:16:18.606232Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "tech_consolidated_QC.duplicated(subset=['ES_name', 'type']).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:18.809960Z",
     "start_time": "2024-07-03T20:16:18.798819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Unit conversion file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# # Allows to keep formulas in Excel files\n",
    "# from openpyxl import load_workbook\n",
    "# wb_CH = load_workbook(filename = 'energyscope_data/hidden/tech_unit_conversion_CH.xlsx')\n",
    "# unit_conv_CH = pd.DataFrame(wb_CH[wb_CH.sheetnames[0]].values)\n",
    "# wb_QC = load_workbook(filename = 'energyscope_data/hidden/tech_unit_conversion_QC.xlsx')\n",
    "# unit_conv_QC = pd.DataFrame(wb_QC[wb_QC.sheetnames[0]].values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:19.533758Z",
     "start_time": "2024-07-03T20:16:19.525857Z"
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "# # setting first row as header\n",
    "# new_header_CH = unit_conv_CH.iloc[0]\n",
    "# unit_conv_CH = unit_conv_CH[1:]\n",
    "# unit_conv_CH.columns = new_header_CH\n",
    "# new_header_QC = unit_conv_QC.iloc[0]\n",
    "# unit_conv_QC = unit_conv_QC[1:]\n",
    "# unit_conv_QC.columns = new_header_QC"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:20.229816Z",
     "start_time": "2024-07-03T20:16:20.224477Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:29.452208Z",
     "start_time": "2024-07-03T20:16:28Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unit_conv_CH = pd.read_excel('energyscope_data/QC/hidden/tech_unit_conversion_CH.xlsx')\n",
    "unit_conv_QC = pd.read_excel('energyscope_data/QC/hidden/tech_unit_conversion_QC.xlsx')"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "unit_conv_CH = unit_conv_CH[['ES_name', 'ei_constr_unit', 'ES_constr_unit', 'ei_use_unit', 'ES_use_unit', 'capacity', 'conversion', 'ei_constr_unit_size', 'ES_constr_unit_size', 'Assumptions & Sources']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:30.815429Z",
     "start_time": "2024-07-03T20:16:30.806085Z"
    }
   },
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "# Drop the rows where both the capacity and conversion factors are None\n",
    "unit_conv_CH.drop(unit_conv_CH[(unit_conv_CH.conversion.values == None) & (unit_conv_CH.capacity.values == None)].index, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:31.170405Z",
     "start_time": "2024-07-03T20:16:31.158683Z"
    }
   },
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "### QC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "unit_conv_QC = unit_conv_QC[unit_conv_CH.columns]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:32.517836Z",
     "start_time": "2024-07-03T20:16:32.510711Z"
    }
   },
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "unit_conv_QC.dropna(how='all', axis=0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:32.986775Z",
     "start_time": "2024-07-03T20:16:32.968082Z"
    }
   },
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "# In order to overwrite some conversion factors (same technologies but different factors between CH and QC), we remove from the CH file the factors that are present in both files\n",
    "unit_conv_CH_overwrite = unit_conv_CH.copy()\n",
    "for tech in list(unit_conv_QC.ES_name.unique()):\n",
    "    if tech in list(unit_conv_CH.ES_name.unique()):\n",
    "        unit_conv_CH_overwrite.drop(unit_conv_CH[unit_conv_CH.ES_name == tech].index, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:33.588850Z",
     "start_time": "2024-07-03T20:16:33.549004Z"
    }
   },
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "unit_conv_QC_consolidated = pd.concat([unit_conv_CH_overwrite.drop(unit_conv_CH_overwrite[unit_conv_CH_overwrite.ES_name.isin(tech_not_QC)].index), unit_conv_QC])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:34.037169Z",
     "start_time": "2024-07-03T20:16:34.030094Z"
    }
   },
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model file"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:40.513143Z",
     "start_time": "2024-07-03T20:16:40.500797Z"
    }
   },
   "cell_type": "code",
   "source": "ES_region = 'CH'",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:41.309144Z",
     "start_time": "2024-07-03T20:16:41.289626Z"
    }
   },
   "cell_type": "code",
   "source": "layers_in_out = pd.read_csv(f\"energyscope_data/QC/hidden/layers_in_out_{ES_region}.csv\")",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:16:46.217330Z",
     "start_time": "2024-07-03T20:16:46.193204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if ES_region == 'QC':\n",
    "    model = layers_in_out.melt(id_vars=['ES_name'], value_vars=layers_in_out.columns[1:])\n",
    "    model = model[model['value'] != 0]\n",
    "    model.rename(columns={'ES_name': 'Flow', 'variable': 'Name', 'value': 'Amount'}, inplace=True)\n",
    "elif ES_region == 'CH':\n",
    "    model = layers_in_out\n",
    "else:\n",
    "    raise ValueError('ES_region should be either CH or QC')\n",
    "model[['Name', 'Flow', 'Amount']].to_csv(f'energyscope_data/{ES_region}/model.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Duplicate mapping for mobility models"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:18:07.539070Z",
     "start_time": "2024-07-03T20:18:07.530779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if ES_region == 'QC':\n",
    "    tech_ecoinvent = tech_consolidated_QC.copy(deep=True)\n",
    "    tech_unit_conversion = unit_conv_QC_consolidated.copy(deep=True)\n",
    "    comp = comp_QC.copy(deep=True)\n",
    "elif ES_region == 'CH':\n",
    "    tech_ecoinvent = tech_CH.copy(deep=True)\n",
    "    tech_unit_conversion = unit_conv_CH_overwrite.copy(deep=True)\n",
    "    comp = comp_CH.copy(deep=True)\n",
    "else:\n",
    "    raise ValueError('ES_region should be either CH or QC')"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:18:12.848851Z",
     "start_time": "2024-07-03T20:18:12.840206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tech_ecoinvent.reset_index(drop=True, inplace=True)\n",
    "tech_unit_conversion.reset_index(drop=True, inplace=True)\n",
    "comp.reset_index(drop=True, inplace=True)"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:18:22.224469Z",
     "start_time": "2024-07-03T20:18:22.071257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "assumptions_diff = pd.read_excel(f'energyscope_data/QC/hidden/assumptions_diff_{ES_region}.xlsx')\n",
    "mob_model_private = pd.read_csv(\n",
    "    f\"energyscope_data/QC/hidden/MODELS_OF_TECHNOLOGIES_OF_PRIVATEMOB_ALL_DISTANCES_{ES_region}.csv\", sep=',')\n",
    "if ES_region == 'QC':\n",
    "    mob_model_public = pd.read_csv(\n",
    "        f\"energyscope_data/QC/hidden/MODELS_OF_TECHNOLOGIES_OF_PUBLICMOB_ALL_DISTANCES_{ES_region}.csv\", sep=',')\n",
    "    mob_model_freight = pd.read_csv(\n",
    "        f\"energyscope_data/QC/hidden/MODELS_OF_TECHNOLOGIES_OF_FREIGHTMOB_ALL_DISTANCES_{ES_region}.csv\", sep=',')"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:18:23.585643Z",
     "start_time": "2024-07-03T20:18:23.574023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Gather all non-nan components into a list\n",
    "comp['Components'] = [[e for e in row if e == e] for row in comp.iloc[:, 1:].values.tolist()]\n",
    "comp_dict = dict(zip(comp.ES_name, comp.Components))\n",
    "N_sub_comp_max = 4  # maximum number of subcomponents in the compositions file"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:18:25.334235Z",
     "start_time": "2024-07-03T20:18:25.319472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gen_df_mob_models(df):\n",
    "    df_mobility_models = pd.DataFrame(columns=tech_ecoinvent.columns)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        tech = df.Main_tech.iloc[i]\n",
    "\n",
    "        if tech in list(tech_ecoinvent.ES_name):\n",
    "\n",
    "            j = 1\n",
    "            model = str(df[df.Main_tech == tech][f'Model_{j}'].iloc[0])\n",
    "            while (model != 'nan') & (j < df.shape[1]):\n",
    "                if str(df_mobility_models.index.max()) == 'nan':\n",
    "                    idx = 1\n",
    "                else:\n",
    "                    idx = df_mobility_models.index.max() + 1\n",
    "                df_mobility_models.loc[idx] = [model] + list(tech_ecoinvent[tech_ecoinvent.ES_name == tech].iloc[0, 1:])  # operation\n",
    "                tech_unit_conversion.loc[tech_unit_conversion.index.max() + 1] = [model] + list(tech_unit_conversion[tech_unit_conversion.ES_name == tech].iloc[0,1:])  # update unit conversion Excel files with additional rows for mobility models\n",
    "                dict_ES.loc[dict_ES.index.max() + 1] = [model] + list(dict_ES[dict_ES['Programming name'] == tech].iloc[0,1:])  # update technology dictionary Excel file with additional rows for mobility models\n",
    "                assumptions_diff.loc[assumptions_diff.index.max() + 1] = [model] + list(assumptions_diff[assumptions_diff.ES_name == tech].iloc[0,1:])  # update unit conversion Excel files with additional rows for mobility models\n",
    "\n",
    "                if tech in comp_dict.keys():\n",
    "\n",
    "                    N_sub_comp = len(comp_dict[tech])\n",
    "                    subscript_comp_list = []\n",
    "\n",
    "                    for i, sub_comp in enumerate(comp_dict[tech]):\n",
    "                        subscript_comp = sub_comp.replace(tech, '')\n",
    "                        subscript_comp_list.append(subscript_comp)\n",
    "                        df_mobility_models.loc[df_mobility_models.index.max() + 1] = [model + subscript_comp] + list(tech_ecoinvent[tech_ecoinvent.ES_name == sub_comp].iloc[0,1:])  # construction component idx\n",
    "                        tech_unit_conversion.loc[tech_unit_conversion.index.max() + 1] = [model + subscript_comp] + list(tech_unit_conversion[tech_unit_conversion.ES_name == sub_comp].iloc[0,1:])  # update unit conversion Excel files\n",
    "                        assumptions_diff.loc[assumptions_diff.index.max() + 1] = [model + subscript_comp] + list(assumptions_diff[assumptions_diff.ES_name == sub_comp].iloc[0,1:])  # update unit conversion Excel files\n",
    "\n",
    "                    comp.loc[comp.index.max() + 1] = [model] + [model + a for a in subscript_comp_list] + [np.nan] * (N_sub_comp_max - N_sub_comp) + [[model + a for a in subscript_comp_list]]  # update the compositions Excel files\n",
    "                    comp_dict[model] = [model + a for a in subscript_comp_list]\n",
    "\n",
    "                else:\n",
    "                    df_mobility_models.loc[idx + 1] = [model] + list(\n",
    "                        tech_ecoinvent[tech_ecoinvent.ES_name == tech].iloc[1, 1:])  # construction\n",
    "                j += 1\n",
    "                if j < df.shape[1]:\n",
    "                    model = str(df[df.Main_tech == tech][f'Model_{j}'].iloc[0])\n",
    "\n",
    "    return df_mobility_models"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:18:27.204423Z",
     "start_time": "2024-07-03T20:18:27.195674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if ES_region == 'QC':\n",
    "    basic_tech_to_remove = list(mob_model_private.Main_tech) + list(mob_model_public.Main_tech) + list(\n",
    "        mob_model_freight.Main_tech)\n",
    "else:\n",
    "    basic_tech_to_remove = list(mob_model_private.Main_tech)\n",
    "\n",
    "for tech in basic_tech_to_remove:\n",
    "    if tech in comp_dict.keys():  # add the subcomponents to the list of technologies to remove\n",
    "        for sub_comp in comp_dict[tech]:\n",
    "            basic_tech_to_remove.append(sub_comp)"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:18:28.718752Z",
     "start_time": "2024-07-03T20:18:28.695576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create df of mapping with mobility models\n",
    "df_mobility_models_private = gen_df_mob_models(mob_model_private)\n",
    "if ES_region == 'QC':\n",
    "    df_mobility_models_public = gen_df_mob_models(mob_model_public)\n",
    "    df_mobility_models_freight = gen_df_mob_models(mob_model_freight)\n",
    "\n",
    "# Remove the mobility basic technologies\n",
    "tech_ecoinvent.drop(tech_ecoinvent[tech_ecoinvent.ES_name.isin(basic_tech_to_remove)].index, inplace=True)\n",
    "tech_unit_conversion.drop(tech_unit_conversion[tech_unit_conversion.ES_name.isin(basic_tech_to_remove)].index,\n",
    "                          inplace=True)\n",
    "comp.drop(comp[comp.ES_name.isin(basic_tech_to_remove)].index, inplace=True)\n",
    "assumptions_diff.drop(assumptions_diff[assumptions_diff.ES_name.isin(basic_tech_to_remove)].index, inplace=True)"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:18:33.846654Z",
     "start_time": "2024-07-03T20:18:33.836261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mob_model_comp = []  # list of components for mobility technologies composition (to remove)\n",
    "\n",
    "if ES_region == 'CH':\n",
    "    mob_tech_list = list(mob_model_private.Main_tech)\n",
    "else:\n",
    "    mob_tech_list = list(mob_model_private.Main_tech) + list(mob_model_public.Main_tech) + list(\n",
    "        mob_model_freight.Main_tech)\n",
    "\n",
    "for mob_tech in mob_tech_list:\n",
    "    if mob_tech in comp_dict.keys():\n",
    "        for sub_comp in comp_dict[mob_tech]:\n",
    "            mob_model_comp.append(sub_comp)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "tech_ecoinvent.drop(tech_ecoinvent[tech_ecoinvent.ES_name.isin(mob_model_comp)].index, inplace=True)"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:18:34.556020Z",
     "start_time": "2024-07-03T20:18:34.535131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Concatenate the overall df's\n",
    "if ES_region == 'CH':\n",
    "    tech_ecoinvent = pd.concat([tech_ecoinvent,\n",
    "                                df_mobility_models_private])\n",
    "else:\n",
    "    tech_ecoinvent = pd.concat([tech_ecoinvent,\n",
    "                                df_mobility_models_private,\n",
    "                                df_mobility_models_public,\n",
    "                                df_mobility_models_freight])\n",
    "tech_ecoinvent = tech_ecoinvent.sort_values('ES_name').reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Mapping file with both technologies and resources"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:18:38.199643Z",
     "start_time": "2024-07-03T20:18:38.154648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = pd.read_csv(f\"energyscope_data/QC/hidden/res_ecoinvent.csv\")\n",
    "flows = pd.read_csv('energyscope_data/QC/hidden/flows_ecoinvent.csv') "
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:18:44.215712Z",
     "start_time": "2024-07-03T20:18:38.834305Z"
    }
   },
   "cell_type": "code",
   "source": "db_flows = concatenate_databases(list(flows.Database.unique()))",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:18:44.231800Z",
     "start_time": "2024-07-03T20:18:44.215712Z"
    }
   },
   "cell_type": "code",
   "source": "flows['Type'] = len(flows) * ['Flow']",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:20:28.501860Z",
     "start_time": "2024-07-03T20:20:28.488702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the user-defined ranking\n",
    "if ES_region == 'QC':\n",
    "    my_ranking = [\n",
    "        'CA-QC',  # Quebec\n",
    "        'CA',  # Canada\n",
    "        'CA-ON',  # Other canadian provinces \n",
    "        'CA-AB',\n",
    "        'CA-BC',\n",
    "        'CA-MB',\n",
    "        'CA-NB',\n",
    "        'CA-NF',\n",
    "        'CA-NS',\n",
    "        'CA-NT',\n",
    "        'CA-NU',\n",
    "        'CA-PE',\n",
    "        'CAZ',  # Canada - Australia - New Zealand\n",
    "        'RNA',  # North America\n",
    "        'US',  # United States\n",
    "        'USA',  # United States\n",
    "        'GLO',  # Global average \n",
    "        'RoW',  # Rest of the world\n",
    "    ]\n",
    "elif ES_region == 'CH':\n",
    "    my_ranking = [\n",
    "        'CH', \n",
    "        'RER', \n",
    "        'IAI Area, EU27 & EFTA',\n",
    "        'NEU',\n",
    "        'EUR',\n",
    "        'GLO',\n",
    "        'RoW'\n",
    "    ]\n",
    "else:\n",
    "    raise ValueError('ES_region should be either CH or QC')"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:20:33.760784Z",
     "start_time": "2024-07-03T20:20:32.286015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flows = change_location_mapping_file(\n",
    "    flows,\n",
    "    my_ranking,\n",
    "    db_flows,\n",
    "    ES_region,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:20:34.801909Z",
     "start_time": "2024-07-03T20:20:34.778969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res.drop(columns=['Description'], inplace=True)\n",
    "res.dropna(subset=['product_name'], inplace=True)\n",
    "res['type'] = len(res) * ['Resource']\n",
    "mapping = pd.concat([tech_ecoinvent, res], ignore_index=True).rename(\n",
    "    columns={'ES_name': 'Name', 'type': 'Type', 'product_name': 'Product', 'activity_name': 'Activity', 'region': 'Location', 'unit': 'Unit', 'database': 'Database'})\n",
    "mapping = pd.concat([mapping, flows])"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Adapting trucks to carculator names"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:20:36.578423Z",
     "start_time": "2024-07-03T20:20:36.562270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def change_truck_name(row):\n",
    "    if row.Name.startswith('LCV_') | row.Name.startswith('SEMI_SH_'):\n",
    "        if row.Type == 'Operation':\n",
    "            row.Product = row.Product.replace('freight, lorry', 'truck')\n",
    "            row.Activity = row.Activity.replace('freight, lorry', 'truck')\n",
    "        \n",
    "        elif row.Type == 'Construction':\n",
    "            row.Product = row.Product.replace('Light duty ', '')\n",
    "            row.Activity = row.Activity.replace('Light duty ', '')\n",
    "            \n",
    "            row.Product = row.Product.replace('Medium duty ', '')\n",
    "            row.Activity = row.Activity.replace('Medium duty ', '')\n",
    "        \n",
    "        row.Product = row.Product.replace(' gross weight', '')\n",
    "        row.Activity = row.Activity.replace(' gross weight', '')\n",
    "        \n",
    "        row.Product = row.Product.replace('EURO-VI', 'Euro-6')\n",
    "        row.Activity = row.Activity.replace('EURO-VI', 'Euro-6')\n",
    "        \n",
    "        row.Location = row.Location.replace('RER', 'CH')\n",
    "        \n",
    "        if 'urban delivery' in row.Activity:\n",
    "            row.Database = row.Database.replace('lci-long_haul_trucks', 'urban delivery_truck')\n",
    "        elif 'regional delivery' in row.Activity:\n",
    "            row.Database = row.Database.replace('lci-long_haul_trucks', 'regional delivery_truck')\n",
    "        else:\n",
    "            raise ValueError('Truck type not recognized')\n",
    "        \n",
    "    return row"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:20:38.625633Z",
     "start_time": "2024-07-03T20:20:38.570944Z"
    }
   },
   "cell_type": "code",
   "source": "mapping = mapping.apply(change_truck_name, axis=1)",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:20:42.673039Z",
     "start_time": "2024-07-03T20:20:42.649004Z"
    }
   },
   "cell_type": "code",
   "source": "mapping.to_csv(f\"energyscope_data/{ES_region}/mapping.csv\", index=False)",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Composition file"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:21:56.633378Z",
     "start_time": "2024-07-03T20:21:56.616782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "comp.rename(columns={'ES_name': 'Name'}, inplace=True)\n",
    "comp[['Name', 'Components']].to_csv(f\"energyscope_data/{ES_region}/technology_compositions.csv\", index=False)"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Unit conversion and assumptions files"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:22:26.048132Z",
     "start_time": "2024-07-03T20:22:25.880797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res_unit_conversion = pd.read_excel(\"energyscope_data/QC/hidden/res_unit_conversion.xlsx\")\n",
    "other_unit_conversion = pd.read_csv(\"energyscope_data/QC/hidden/other_unit_conversion.csv\")\n",
    "lifetime = assumptions_diff.copy(deep=True)"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:22:27.575482Z",
     "start_time": "2024-07-03T20:22:27.557482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tech_unit_conversion_melted = tech_unit_conversion[['ES_name', 'capacity', 'conversion', 'ei_constr_unit', 'ES_constr_unit', 'ei_use_unit', 'ES_use_unit']].rename(\n",
    "    columns={'ES_name': 'Name', 'capacity': 'Construction', 'conversion': 'Operation'}\n",
    ").melt(\n",
    "    id_vars='Name',\n",
    "    value_vars=['Construction', 'Operation'],\n",
    "    var_name='Type',\n",
    "    value_name='Value'\n",
    ").sort_values('Name').dropna(subset='Value')"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:22:28.337427Z",
     "start_time": "2024-07-03T20:22:28.313751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tech_unit_conversion_melted_constr = tech_unit_conversion_melted[tech_unit_conversion_melted.Type == 'Construction']\n",
    "tech_unit_conversion_melted_op = tech_unit_conversion_melted[tech_unit_conversion_melted.Type == 'Operation']\n",
    "tech_unit_conversion_melted_constr = tech_unit_conversion_melted_constr.merge(tech_unit_conversion[['ES_name', 'ei_constr_unit', 'ES_constr_unit']], left_on='Name', right_on='ES_name').rename(columns={'ei_constr_unit': 'To', 'ES_constr_unit': 'From'}).drop(columns='ES_name')\n",
    "tech_unit_conversion_melted_op = tech_unit_conversion_melted_op.merge(tech_unit_conversion[['ES_name', 'ei_use_unit', 'ES_use_unit']], left_on='Name', right_on='ES_name').rename(columns={'ei_use_unit': 'To', 'ES_use_unit': 'From'}).drop(columns='ES_name')\n",
    "tech_unit_conversion_melted = pd.concat([tech_unit_conversion_melted_constr, tech_unit_conversion_melted_op], ignore_index=True).sort_values('Name')"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:22:30.344964Z",
     "start_time": "2024-07-03T20:22:30.325219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res_unit_conversion_melted = res_unit_conversion[['ES_name', 'conversion', 'ei_unit', 'ES_unit']].rename(\n",
    "    columns={'ES_name': 'Name', 'conversion': 'Resource'}\n",
    ").melt(\n",
    "    id_vars='Name', \n",
    "    value_vars=['Resource'],\n",
    "    var_name='Type', \n",
    "    value_name='Value'\n",
    ").sort_values('Name').dropna(subset='Value')"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:22:30.776628Z",
     "start_time": "2024-07-03T20:22:30.766496Z"
    }
   },
   "cell_type": "code",
   "source": "res_unit_conversion_melted = res_unit_conversion_melted.merge(res_unit_conversion[['ES_name', 'ei_unit', 'ES_unit']], left_on='Name', right_on='ES_name').rename(columns={'ei_unit': 'To', 'ES_unit': 'From'}).drop(columns='ES_name')",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:22:31.352707Z",
     "start_time": "2024-07-03T20:22:31.336082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unit_conversion = pd.concat([tech_unit_conversion_melted, \n",
    "                             res_unit_conversion_melted, \n",
    "                             other_unit_conversion[['Name', 'Value', 'Type', 'From', 'To']],\n",
    "                             ], ignore_index=True).sort_values('Name')"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:22:54.552051Z",
     "start_time": "2024-07-03T20:22:54.535598Z"
    }
   },
   "cell_type": "code",
   "source": "unit_conversion.to_csv(f\"energyscope_data/{ES_region}/unit_conversion.csv\", index=False)",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T20:22:55.643333Z",
     "start_time": "2024-07-03T20:22:55.623882Z"
    }
   },
   "cell_type": "code",
   "source": "lifetime[['ES_name', 'lifetime_ES', 'lifetime_ei']].rename(columns={'ES_name': 'Name', 'lifetime_ES': 'ESM', 'lifetime_ei': 'LCA'}).to_csv(f\"energyscope_data/{ES_region}/lifetime.csv\", index=False)",
   "outputs": [],
   "execution_count": 55
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
