{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Consolidating several mappings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bw2data as bd\n",
    "from mescal import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:12.693925Z",
     "start_time": "2024-06-27T18:40:06.530508Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:12.816887Z",
     "start_time": "2024-06-27T18:40:12.693925Z"
    }
   },
   "cell_type": "code",
   "source": "bd.projects.set_current('ei3.8-mescal')",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "tech_CH = pd.read_csv('energyscope_data/hidden/tech_CH.csv') # mapping from ecoinvent 3.8 for CH\n",
    "tech_QC = pd.read_csv('energyscope_data/hidden/tech_QC.csv') # mapping from ecoinvent 3.8 and premise specific for QC\n",
    "comp_CH = pd.read_excel('energyscope_data/hidden/techno_compositions_CH.xlsx') # list of compositions of technologies with premise mapping for CH\n",
    "comp_QC = pd.read_excel('energyscope_data/hidden/techno_compositions_QC.xlsx') # list of compositions of technologies with premise mapping for QC\n",
    "dict_ES = pd.read_csv('energyscope_data/hidden/Technology_Dictionary_v2.csv')\n",
    "region_tech_ES = pd.read_excel('energyscope_data/hidden/Technologies_ES_version.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:12.907868Z",
     "start_time": "2024-06-27T18:40:12.816887Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:12.924271Z",
     "start_time": "2024-06-27T18:40:12.910906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if 'Validation' in tech_CH.columns:\n",
    "    tech_CH.drop(columns='Validation', inplace=True)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mapping file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:12.944541Z",
     "start_time": "2024-06-27T18:40:12.925783Z"
    }
   },
   "cell_type": "code",
   "source": "len(tech_CH.ES_name.unique())",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### QC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start from the consolidated file of CH and add/replace what is in the tech_QC additional mapping, and filter what was only for CH using the list of technologies from ES-QC."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "region_tech_ES.dropna(subset=['ES_version'], inplace=True) # OTHER_BIOMASS to remove"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:12.954782Z",
     "start_time": "2024-06-27T18:40:12.944541Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "list_tech_QC = list(region_tech_ES[region_tech_ES.ES_version.str.contains('CA')].tech_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:12.965225Z",
     "start_time": "2024-06-27T18:40:12.954782Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:12.974767Z",
     "start_time": "2024-06-27T18:40:12.965225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sub_comp_CH = list(set([x for xs in comp_CH.iloc[:, 1:].values.tolist() for x in xs])) # list of all subcomponents for CH\n",
    "sub_comp_QC = list(set([x for xs in comp_QC.iloc[:, 1:].values.tolist() for x in xs])) # list of all subcomponents for QC"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove technologies that are not in ES-QC\n",
    "tech_not_QC = []\n",
    "\n",
    "# Operation\n",
    "for tech in list(tech_CH[tech_CH.type == 'Operation'].ES_name):\n",
    "    if tech not in list_tech_QC:\n",
    "        tech_not_QC.append(tech)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Construction\n",
    "for tech in list(tech_CH[tech_CH.type == 'Construction'].ES_name):\n",
    "    if tech in sub_comp_CH:\n",
    "        if tech not in sub_comp_QC:\n",
    "            tech_not_QC.append(tech)\n",
    "        else:\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:12.989279Z",
     "start_time": "2024-06-27T18:40:12.974767Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "list(set(tech_not_QC))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:13.000517Z",
     "start_time": "2024-06-27T18:40:12.989279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRAIN_FREIGHT_NG_LOC',\n",
       " 'TRAIN_FREIGHT_NG',\n",
       " 'COACH_FC_HYBRID_CH4',\n",
       " 'BUS_CNG_STOICH',\n",
       " 'TRAIN_NG',\n",
       " 'CAR_HEV_LOCAL',\n",
       " 'CAR_DME_D10_LONGD',\n",
       " 'CAR_ETOH_E85_LONGD',\n",
       " 'CAR_FC_CH4_LOCAL',\n",
       " 'BUS_FC_HYBRID_H2',\n",
       " 'TRAIN_FREIGHT_WAG',\n",
       " 'CAR_ETOH_E10_LOCAL',\n",
       " 'CAR_ETOH_E85_LOCAL',\n",
       " 'CAR_DIESEL_LOCAL',\n",
       " 'CAR_PHEV_LOCAL',\n",
       " 'CAR_MEOH_LONGD',\n",
       " 'TRUCK',\n",
       " 'COACH_CNG_STOICH',\n",
       " 'TRUCK_EV',\n",
       " 'COMMUTER_RAIL_ELEC',\n",
       " 'CAR_BEV_MEDRANGE_LOCAL',\n",
       " 'CAR_NG_LONGD',\n",
       " 'CAR_BEV_LOWRANGE',\n",
       " 'COACH_HY_DIESEL',\n",
       " 'CAR_DME_D10_LOCAL',\n",
       " 'COMMUTER_RAIL_DIESEL',\n",
       " 'TRAIN_FREIGHT',\n",
       " 'CAR_BEV_MEDRANGE_LONGD',\n",
       " 'CAR_FC_H2_LONGD',\n",
       " 'CAR_GASOLINE_LONGD',\n",
       " 'CAR_HEV_LONGD',\n",
       " 'TRAIN_FREIGHT_LOC',\n",
       " 'CAR_NG_LOCAL',\n",
       " 'CAR_PHEV_LONGD',\n",
       " 'CAR_GASOLINE_LOCAL',\n",
       " 'COACH_FC_HYBRID_H2',\n",
       " 'TRUCK_FC',\n",
       " 'TRAIN_ELEC',\n",
       " 'CAR_FC_CH4_LONGD',\n",
       " 'TRAIN_FREIGHT_NG_WAG',\n",
       " 'CAR_DIESEL_LONGD',\n",
       " 'BUS_FC_HYBRID_CH4',\n",
       " 'WIND',\n",
       " 'CAR_ETOH_E10_LONGD',\n",
       " 'TRUCK_SNG',\n",
       " 'CAR_MEOH_LOCAL',\n",
       " 'CAR_FC_H2_LOCAL']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "tech_CH_filtered = tech_CH.drop(index=tech_CH[tech_CH.ES_name.isin(tech_not_QC)].index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:13.011054Z",
     "start_time": "2024-06-27T18:40:13.000517Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove the LCI datasets that need to be updated from the CH list\n",
    "update_constr = []\n",
    "for tech in list(tech_CH[tech_CH.type == 'Construction'].ES_name):\n",
    "    if (tech in list(tech_CH[tech_CH.type == 'Construction'].ES_name)) & (tech in list(tech_QC[tech_QC.type == 'Construction'].ES_name)):\n",
    "        update_constr.append(tech)\n",
    "\n",
    "update_op = []\n",
    "for tech in list(tech_CH[tech_CH.type == 'Operation'].ES_name):\n",
    "    if (tech in list(tech_CH[tech_CH.type == 'Operation'].ES_name)) & (tech in list(tech_QC[tech_QC.type == 'Operation'].ES_name)):\n",
    "        update_op.append(tech)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:13.392607Z",
     "start_time": "2024-06-27T18:40:13.011054Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "tech_CH_filtered.drop(index=tech_CH_filtered[(tech_CH_filtered.ES_name.isin(update_constr)) & (tech_CH_filtered.type == 'Construction')].index, inplace=True)\n",
    "tech_CH_filtered.drop(index=tech_CH_filtered[(tech_CH_filtered.ES_name.isin(update_op)) & (tech_CH_filtered.type == 'Operation')].index, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:13.406648Z",
     "start_time": "2024-06-27T18:40:13.392607Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "tech_consolidated_QC = pd.concat([tech_CH_filtered, tech_QC])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:13.435988Z",
     "start_time": "2024-06-27T18:40:13.408822Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "tech_consolidated_QC.duplicated(subset=['ES_name', 'type']).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:13.448417Z",
     "start_time": "2024-06-27T18:40:13.435988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Unit conversion file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# # Allows to keep formulas in Excel files\n",
    "# from openpyxl import load_workbook\n",
    "# wb_CH = load_workbook(filename = 'energyscope_data/hidden/tech_unit_conversion_CH.xlsx')\n",
    "# unit_conv_CH = pd.DataFrame(wb_CH[wb_CH.sheetnames[0]].values)\n",
    "# wb_QC = load_workbook(filename = 'energyscope_data/hidden/tech_unit_conversion_QC.xlsx')\n",
    "# unit_conv_QC = pd.DataFrame(wb_QC[wb_QC.sheetnames[0]].values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:13.456077Z",
     "start_time": "2024-06-27T18:40:13.449434Z"
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "# # setting first row as header\n",
    "# new_header_CH = unit_conv_CH.iloc[0]\n",
    "# unit_conv_CH = unit_conv_CH[1:]\n",
    "# unit_conv_CH.columns = new_header_CH\n",
    "# new_header_QC = unit_conv_QC.iloc[0]\n",
    "# unit_conv_QC = unit_conv_QC[1:]\n",
    "# unit_conv_QC.columns = new_header_QC"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:13.468217Z",
     "start_time": "2024-06-27T18:40:13.456077Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:14.090930Z",
     "start_time": "2024-06-27T18:40:13.468217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unit_conv_CH = pd.read_excel('energyscope_data/hidden/tech_unit_conversion_CH.xlsx')\n",
    "unit_conv_QC = pd.read_excel('energyscope_data/hidden/tech_unit_conversion_QC.xlsx')"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "unit_conv_CH = unit_conv_CH[['ES_name', 'ei_constr_unit', 'ES_constr_unit', 'ei_use_unit', 'ES_use_unit', 'capacity', 'conversion', 'ei_constr_unit_size', 'ES_constr_unit_size', 'Assumptions & Sources']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:14.107275Z",
     "start_time": "2024-06-27T18:40:14.091944Z"
    }
   },
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "# Drop the rows where both the capacity and conversion factors are None\n",
    "unit_conv_CH.drop(unit_conv_CH[(unit_conv_CH.conversion.values == None) & (unit_conv_CH.capacity.values == None)].index, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:14.132855Z",
     "start_time": "2024-06-27T18:40:14.108877Z"
    }
   },
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "### QC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "unit_conv_QC = unit_conv_QC[unit_conv_CH.columns]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:14.144902Z",
     "start_time": "2024-06-27T18:40:14.132855Z"
    }
   },
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "unit_conv_QC.dropna(how='all', axis=0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:14.164099Z",
     "start_time": "2024-06-27T18:40:14.147616Z"
    }
   },
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "# In order to overwrite some conversion factors (same technologies but different factors between CH and QC), we remove from the CH file the factors that are present in both files\n",
    "unit_conv_CH_overwrite = unit_conv_CH.copy()\n",
    "for tech in list(unit_conv_QC.ES_name.unique()):\n",
    "    if tech in list(unit_conv_CH.ES_name.unique()):\n",
    "        unit_conv_CH_overwrite.drop(unit_conv_CH[unit_conv_CH.ES_name == tech].index, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:14.218798Z",
     "start_time": "2024-06-27T18:40:14.164099Z"
    }
   },
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "unit_conv_QC_consolidated = pd.concat([unit_conv_CH_overwrite.drop(unit_conv_CH_overwrite[unit_conv_CH_overwrite.ES_name.isin(tech_not_QC)].index), unit_conv_QC])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:14.229147Z",
     "start_time": "2024-06-27T18:40:14.218798Z"
    }
   },
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model file"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:14.261744Z",
     "start_time": "2024-06-27T18:40:14.229147Z"
    }
   },
   "cell_type": "code",
   "source": "layers_in_out = pd.read_csv(\"energyscope_data/hidden/layers_in_out.csv\")",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:14.322547Z",
     "start_time": "2024-06-27T18:40:14.261744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = layers_in_out.melt(id_vars=['ES_name'], value_vars=layers_in_out.columns[1:])\n",
    "model = model[model['value'] != 0]\n",
    "model.rename(columns={'ES_name': 'Flow', 'variable': 'Name', 'value': 'Amount'}, inplace=True)\n",
    "model[['Name', 'Flow', 'Amount']].to_csv('energyscope_data/model.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Duplicate mapping for mobility models"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:14.334201Z",
     "start_time": "2024-06-27T18:40:14.322547Z"
    }
   },
   "cell_type": "code",
   "source": "ES_region = 'QC'",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:14.350468Z",
     "start_time": "2024-06-27T18:40:14.334201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if ES_region == 'QC':\n",
    "    tech_ecoinvent = tech_consolidated_QC.copy(deep=True)\n",
    "    tech_unit_conversion = unit_conv_QC_consolidated.copy(deep=True)\n",
    "    comp = comp_QC.copy(deep=True)\n",
    "elif ES_region == 'CH':\n",
    "    tech_ecoinvent = tech_CH_filtered.copy(deep=True)\n",
    "    tech_unit_conversion = unit_conv_CH_overwrite.copy(deep=True)\n",
    "    comp = comp_CH.copy(deep=True)\n",
    "else:\n",
    "    raise ValueError('ES_region should be either CH or QC')"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:14.365147Z",
     "start_time": "2024-06-27T18:40:14.350468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tech_ecoinvent.reset_index(drop=True, inplace=True)\n",
    "tech_unit_conversion.reset_index(drop=True, inplace=True)\n",
    "comp.reset_index(drop=True, inplace=True)"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:14.578510Z",
     "start_time": "2024-06-27T18:40:14.365147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "assumptions_diff = pd.read_excel(f'energyscope_data/hidden/assumptions_diff_{ES_region}.xlsx')\n",
    "mob_model_private = pd.read_csv(\n",
    "    f\"energyscope_data/hidden/MODELS_OF_TECHNOLOGIES_OF_PRIVATEMOB_ALL_DISTANCES_{ES_region}.csv\", sep=',')\n",
    "if ES_region == 'QC':\n",
    "    mob_model_public = pd.read_csv(f\"energyscope_data/hidden/MODELS_OF_TECHNOLOGIES_OF_PUBLICMOB_ALL_DISTANCES_{ES_region}.csv\", sep=',')\n",
    "    mob_model_freight = pd.read_csv(f\"energyscope_data/hidden/MODELS_OF_TECHNOLOGIES_OF_FREIGHTMOB_ALL_DISTANCES_{ES_region}.csv\", sep=',')"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:14.589954Z",
     "start_time": "2024-06-27T18:40:14.578510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Gather all non-nan components into a list\n",
    "comp['Components'] = [[e for e in row if e == e] for row in comp.iloc[:, 1:].values.tolist()]\n",
    "comp_dict = dict(zip(comp.ES_name, comp.Components))\n",
    "N_sub_comp_max = 4  # maximum number of subcomponents in the compositions file"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:14.618103Z",
     "start_time": "2024-06-27T18:40:14.596406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gen_df_mob_models(df):\n",
    "    df_mobility_models = pd.DataFrame(columns=tech_ecoinvent.columns)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        tech = df.Main_tech.iloc[i]\n",
    "\n",
    "        if tech in list(tech_ecoinvent.ES_name):\n",
    "\n",
    "            j = 1\n",
    "            model = str(df[df.Main_tech == tech][f'Model_{j}'].iloc[0])\n",
    "            while (model != 'nan') & (j < df.shape[1]):\n",
    "                if str(df_mobility_models.index.max()) == 'nan':\n",
    "                    idx = 1\n",
    "                else:\n",
    "                    idx = df_mobility_models.index.max() + 1\n",
    "                df_mobility_models.loc[idx] = [model] + list(tech_ecoinvent[tech_ecoinvent.ES_name == tech].iloc[0, 1:])  # operation\n",
    "                tech_unit_conversion.loc[tech_unit_conversion.index.max() + 1] = [model] + list(tech_unit_conversion[tech_unit_conversion.ES_name == tech].iloc[0,1:])  # update unit conversion Excel files with additional rows for mobility models\n",
    "                dict_ES.loc[dict_ES.index.max() + 1] = [model] + list(dict_ES[dict_ES['Programming name'] == tech].iloc[0,1:])  # update technology dictionary Excel file with additional rows for mobility models\n",
    "                assumptions_diff.loc[assumptions_diff.index.max() + 1] = [model] + list(assumptions_diff[assumptions_diff.ES_name == tech].iloc[0,1:])  # update unit conversion Excel files with additional rows for mobility models\n",
    "\n",
    "                if tech in comp_dict.keys():\n",
    "\n",
    "                    N_sub_comp = len(comp_dict[tech])\n",
    "                    subscript_comp_list = []\n",
    "\n",
    "                    for i, sub_comp in enumerate(comp_dict[tech]):\n",
    "                        subscript_comp = sub_comp.replace(tech, '')\n",
    "                        subscript_comp_list.append(subscript_comp)\n",
    "                        df_mobility_models.loc[df_mobility_models.index.max() + 1] = [model + subscript_comp] + list(tech_ecoinvent[tech_ecoinvent.ES_name == sub_comp].iloc[0,1:])  # construction component idx\n",
    "                        tech_unit_conversion.loc[tech_unit_conversion.index.max() + 1] = [model + subscript_comp] + list(tech_unit_conversion[tech_unit_conversion.ES_name == sub_comp].iloc[0,1:])  # update unit conversion Excel files\n",
    "                        assumptions_diff.loc[assumptions_diff.index.max() + 1] = [model + subscript_comp] + list(assumptions_diff[assumptions_diff.ES_name == sub_comp].iloc[0,1:])  # update unit conversion Excel files\n",
    "\n",
    "                    comp.loc[comp.index.max() + 1] = [model] + [model + a for a in subscript_comp_list] + [np.nan] * (N_sub_comp_max - N_sub_comp) + [[model + a for a in subscript_comp_list]]  # update the compositions Excel files\n",
    "                    comp_dict[model] = [model + a for a in subscript_comp_list]\n",
    "\n",
    "                else:\n",
    "                    df_mobility_models.loc[idx + 1] = [model] + list(\n",
    "                        tech_ecoinvent[tech_ecoinvent.ES_name == tech].iloc[1, 1:])  # construction\n",
    "                j += 1\n",
    "                if j < df.shape[1]:\n",
    "                    model = str(df[df.Main_tech == tech][f'Model_{j}'].iloc[0])\n",
    "\n",
    "    return df_mobility_models"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:14.634725Z",
     "start_time": "2024-06-27T18:40:14.620551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if ES_region == 'QC':\n",
    "    basic_tech_to_remove = list(mob_model_private.Main_tech) + list(mob_model_public.Main_tech) + list(\n",
    "        mob_model_freight.Main_tech)\n",
    "else:\n",
    "    basic_tech_to_remove = list(mob_model_private.Main_tech)\n",
    "\n",
    "for tech in basic_tech_to_remove:\n",
    "    if tech in comp_dict.keys():  # add the subcomponents to the list of technologies to remove\n",
    "        for sub_comp in comp_dict[tech]:\n",
    "            basic_tech_to_remove.append(sub_comp)"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:16.793632Z",
     "start_time": "2024-06-27T18:40:14.634725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create df of mapping with mobility models\n",
    "df_mobility_models_private = gen_df_mob_models(mob_model_private)\n",
    "if ES_region == 'QC':\n",
    "    df_mobility_models_public = gen_df_mob_models(mob_model_public)\n",
    "    df_mobility_models_freight = gen_df_mob_models(mob_model_freight)\n",
    "\n",
    "# Remove the mobility basic technologies\n",
    "tech_ecoinvent.drop(tech_ecoinvent[tech_ecoinvent.ES_name.isin(basic_tech_to_remove)].index, inplace=True)\n",
    "tech_unit_conversion.drop(tech_unit_conversion[tech_unit_conversion.ES_name.isin(basic_tech_to_remove)].index,\n",
    "                          inplace=True)\n",
    "comp.drop(comp[comp.ES_name.isin(basic_tech_to_remove)].index, inplace=True)\n",
    "assumptions_diff.drop(assumptions_diff[assumptions_diff.ES_name.isin(basic_tech_to_remove)].index, inplace=True)"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:16.804089Z",
     "start_time": "2024-06-27T18:40:16.793632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mob_model_comp = []  # list of components for mobility technologies composition (to remove)\n",
    "\n",
    "if ES_region == 'CH':\n",
    "    mob_tech_list = list(mob_model_private.Main_tech)\n",
    "else:\n",
    "    mob_tech_list = list(mob_model_private.Main_tech) + list(mob_model_public.Main_tech) + list(\n",
    "        mob_model_freight.Main_tech)\n",
    "\n",
    "for mob_tech in mob_tech_list:\n",
    "    if mob_tech in comp_dict.keys():\n",
    "        for sub_comp in comp_dict[mob_tech]:\n",
    "            mob_model_comp.append(sub_comp)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "tech_ecoinvent.drop(tech_ecoinvent[tech_ecoinvent.ES_name.isin(mob_model_comp)].index, inplace=True)"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:16.845468Z",
     "start_time": "2024-06-27T18:40:16.805189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Concatenate the overall df's\n",
    "if ES_region == 'CH':\n",
    "    tech_ecoinvent = pd.concat([tech_ecoinvent,\n",
    "                                df_mobility_models_private])\n",
    "else:\n",
    "    tech_ecoinvent = pd.concat([tech_ecoinvent,\n",
    "                                df_mobility_models_private,\n",
    "                                df_mobility_models_public,\n",
    "                                df_mobility_models_freight])\n",
    "tech_ecoinvent = tech_ecoinvent.sort_values('ES_name').reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Mapping file with both technologies and resources"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:16.858437Z",
     "start_time": "2024-06-27T18:40:16.845468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = pd.read_csv(f\"energyscope_data/hidden/res_ecoinvent.csv\")\n",
    "flows = pd.read_csv('energyscope_data/hidden/flows_ecoinvent.csv') "
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:23.939459Z",
     "start_time": "2024-06-27T18:40:16.858437Z"
    }
   },
   "cell_type": "code",
   "source": "db_flows = concatenate_databases(list(flows.Database.unique()))",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:23.951733Z",
     "start_time": "2024-06-27T18:40:23.939459Z"
    }
   },
   "cell_type": "code",
   "source": "flows['Type'] = len(flows) * ['Flow']",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:23.979845Z",
     "start_time": "2024-06-27T18:40:23.953788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the user-defined ranking\n",
    "my_ranking = [\n",
    "    'CA-QC',  # Quebec\n",
    "    'CA',  # Canada\n",
    "    'CA-ON',  # Other canadian provinces \n",
    "    'CA-AB',\n",
    "    'CA-BC',\n",
    "    'CA-MB',\n",
    "    'CA-NB',\n",
    "    'CA-NF',\n",
    "    'CA-NS',\n",
    "    'CA-NT',\n",
    "    'CA-NU',\n",
    "    'CA-PE',\n",
    "    'CAZ',  # Canada - Australia - New Zealand\n",
    "    'RNA',  # North America\n",
    "    'US',  # United States\n",
    "    'USA',  # United States\n",
    "    'GLO',  # Global average \n",
    "    'RoW',  # Rest of the world\n",
    "]\n"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:25.175209Z",
     "start_time": "2024-06-27T18:40:23.980598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flows = change_location_mapping_file(\n",
    "    flows,\n",
    "    my_ranking,\n",
    "    db_flows,\n",
    "    'QC',\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:25.243312Z",
     "start_time": "2024-06-27T18:40:25.186333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res.drop(columns=['Description'], inplace=True)\n",
    "res.dropna(subset=['product_name'], inplace=True)\n",
    "res['type'] = len(res) * ['Resource']\n",
    "mapping = pd.concat([tech_ecoinvent, res], ignore_index=True).rename(\n",
    "    columns={'ES_name': 'Name', 'type': 'Type', 'product_name': 'Product', 'activity_name': 'Activity', 'region': 'Location', 'unit': 'Unit', 'database': 'Database'})\n",
    "mapping = pd.concat([mapping, flows])\n",
    "mapping.to_csv(f\"energyscope_data/mapping.csv\", index=False)"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Composition file"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:25.270381Z",
     "start_time": "2024-06-27T18:40:25.249419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "comp.rename(columns={'ES_name': 'Name'}, inplace=True)\n",
    "comp[['Name', 'Components']].to_csv(f\"energyscope_data/technology_compositions.csv\", index=False)"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Unit conversion and assumptions files"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:25.396023Z",
     "start_time": "2024-06-27T18:40:25.270381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res_unit_conversion = pd.read_excel(\"energyscope_data/hidden/res_unit_conversion.xlsx\")\n",
    "other_unit_conversion = pd.read_csv(\"energyscope_data/hidden/other_unit_conversion.csv\")\n",
    "lifetime = assumptions_diff.copy(deep=True)"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:25.414538Z",
     "start_time": "2024-06-27T18:40:25.396023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tech_unit_conversion_melted = tech_unit_conversion[['ES_name', 'capacity', 'conversion', 'ei_constr_unit', 'ES_constr_unit', 'ei_use_unit', 'ES_use_unit']].rename(\n",
    "    columns={'ES_name': 'Name', 'capacity': 'Construction', 'conversion': 'Operation'}\n",
    ").melt(\n",
    "    id_vars='Name',\n",
    "    value_vars=['Construction', 'Operation'],\n",
    "    var_name='Type',\n",
    "    value_name='Value'\n",
    ").sort_values('Name').dropna(subset='Value')"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:25.454558Z",
     "start_time": "2024-06-27T18:40:25.415058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tech_unit_conversion_melted_constr = tech_unit_conversion_melted[tech_unit_conversion_melted.Type == 'Construction']\n",
    "tech_unit_conversion_melted_op = tech_unit_conversion_melted[tech_unit_conversion_melted.Type == 'Operation']\n",
    "tech_unit_conversion_melted_constr = tech_unit_conversion_melted_constr.merge(tech_unit_conversion[['ES_name', 'ei_constr_unit', 'ES_constr_unit']], left_on='Name', right_on='ES_name').rename(columns={'ei_constr_unit': 'To', 'ES_constr_unit': 'From'}).drop(columns='ES_name')\n",
    "tech_unit_conversion_melted_op = tech_unit_conversion_melted_op.merge(tech_unit_conversion[['ES_name', 'ei_use_unit', 'ES_use_unit']], left_on='Name', right_on='ES_name').rename(columns={'ei_use_unit': 'To', 'ES_use_unit': 'From'}).drop(columns='ES_name')\n",
    "tech_unit_conversion_melted = pd.concat([tech_unit_conversion_melted_constr, tech_unit_conversion_melted_op], ignore_index=True).sort_values('Name')"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:25.472493Z",
     "start_time": "2024-06-27T18:40:25.454558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res_unit_conversion_melted = res_unit_conversion[['ES_name', 'conversion', 'ei_unit', 'ES_unit']].rename(\n",
    "    columns={'ES_name': 'Name', 'conversion': 'Resource'}\n",
    ").melt(\n",
    "    id_vars='Name', \n",
    "    value_vars=['Resource'],\n",
    "    var_name='Type', \n",
    "    value_name='Value'\n",
    ").sort_values('Name').dropna(subset='Value')"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:25.486492Z",
     "start_time": "2024-06-27T18:40:25.472493Z"
    }
   },
   "cell_type": "code",
   "source": "res_unit_conversion_melted = res_unit_conversion_melted.merge(res_unit_conversion[['ES_name', 'ei_unit', 'ES_unit']], left_on='Name', right_on='ES_name').rename(columns={'ei_unit': 'To', 'ES_unit': 'From'}).drop(columns='ES_name')",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:25.504511Z",
     "start_time": "2024-06-27T18:40:25.486492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unit_conversion = pd.concat([tech_unit_conversion_melted, \n",
    "                             res_unit_conversion_melted, \n",
    "                             other_unit_conversion[['Name', 'Value', 'Type', 'From', 'To']],\n",
    "                             ], ignore_index=True).sort_values('Name')"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:25.530051Z",
     "start_time": "2024-06-27T18:40:25.506582Z"
    }
   },
   "cell_type": "code",
   "source": "unit_conversion.to_csv(f\"energyscope_data/unit_conversion.csv\", index=False)",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:40:25.545995Z",
     "start_time": "2024-06-27T18:40:25.530051Z"
    }
   },
   "cell_type": "code",
   "source": "lifetime[['ES_name', 'lifetime_ES', 'lifetime_ei']].rename(columns={'ES_name': 'Name', 'lifetime_ES': 'ESM', 'lifetime_ei': 'LCA'}).to_csv(f\"energyscope_data/lifetime.csv\", index=False)",
   "outputs": [],
   "execution_count": 51
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
